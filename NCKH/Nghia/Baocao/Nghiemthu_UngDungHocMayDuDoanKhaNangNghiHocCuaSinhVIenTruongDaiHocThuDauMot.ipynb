{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulr = \"Data_preprocessing_finish.xlsx\"\n",
    "data = pd.read_excel(ulr, sheet_name=\"Nam4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='box', subplots=True, layout=(6, 7), sharex=False, sharey=False)\n",
    "print(\"This gives us a much clearer idea of the distribution of the input attributes:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "data.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot matrix\n",
    "scatter_matrix(data)\n",
    "print(\"Note the diagonal grouping of some pairs of attributes. \\\n",
    "    This suggests a high correlation and a predictable relationship.\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.subplots(4,4,figsize=(25, 15))\n",
    "n = 0\n",
    "for x, c in zip(['Mon1', 'Mon2', 'Mon3'], list(sns.color_palette())):\n",
    "    for y in ['Mon1', 'Mon2', 'Mon3']:  \n",
    "        plt.subplot(3,3,n+1)\n",
    "        sns.scatterplot(x = x, y = y, data = data, color = c, alpha = 0.4)\n",
    "        n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = data.values\n",
    "X = array[:,0:data.shape[1]-1]\n",
    "Y = array[:,data.shape[1]-1]\n",
    "Y = Y.astype('int')\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "# print(\"X_train = \", end=\"\")\n",
    "# print(X_train, end=\"\\n\\n\")\n",
    "# print(\"Y_train = \", end=\"\")\n",
    "# print(Y_train)\n",
    "# print()\n",
    "# print(\"X_validation = \",X_validation, end=\"\\n\\n\")\n",
    "\n",
    "# print(\"Y_validation = \",Y_validation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably get the error \"Unknown label type: 'Unknown' \". So you can add \"Y = Y.astype('int')\" after the line \"Y = array[:,data.shape[1]-1]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('DTC', DecisionTreeClassifier()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "user = []\n",
    "for x in range(1, data.shape[1]):\n",
    "    print(\"nhap diem mon \", x, \": \", end='')\n",
    "    i = float(input())\n",
    "    print(i)\n",
    "    user.append(i)\n",
    "\n",
    "#load model\n",
    "load_model = pickle.load(open('nam4.pkl', 'rb'))\n",
    "\n",
    "results = load_model.predict([user])\n",
    "if(results == 0):   print(\"Có khả năng nghỉ học\")\n",
    "else: print(\"Không có khả năng nghỉ học\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model = pickle.load(open('nam1.pkl', 'rb'))\n",
    "accuracy_score = model.score(X_validation, Y_validation)\n",
    "print(\"accuracy_score = \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "ulr = \"Data_preprocessing_finish.xlsx\"\n",
    "data = pd.read_excel(ulr, sheet_name=\"Nam2\")\n",
    "array = data.values\n",
    "X = array[:,0:data.shape[1]-1]\n",
    "Y = array[:,data.shape[1]-1]\n",
    "Y = Y.astype('int')\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "model = pickle.load(open('nam2.pkl', 'rb'))\n",
    "accuracy_score = model.score(X_validation, Y_validation)\n",
    "print(\"accuracy_score = \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  1.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "ulr = \"Data_preprocessing_finish.xlsx\"\n",
    "data = pd.read_excel(ulr, sheet_name=\"Nam3\")\n",
    "array = data.values\n",
    "X = array[:,0:data.shape[1]-1]\n",
    "Y = array[:,data.shape[1]-1]\n",
    "Y = Y.astype('int')\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "model = pickle.load(open('nam3.pkl', 'rb'))\n",
    "accuracy_score = model.score(X_validation, Y_validation)\n",
    "print(\"accuracy_score = \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "ulr = \"Data_preprocessing_finish.xlsx\"\n",
    "data = pd.read_excel(ulr, sheet_name=\"Nam4\")\n",
    "array = data.values\n",
    "X = array[:,0:data.shape[1]-1]\n",
    "Y = array[:,data.shape[1]-1]\n",
    "Y = Y.astype('int')\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "model = pickle.load(open('nam4.pkl', 'rb'))\n",
    "accuracy_score = model.score(X_validation, Y_validation)\n",
    "print(\"accuracy_score = \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "ulr = \"Data_preprocessing_finish.xlsx\"\n",
    "data = pd.read_excel(ulr, sheet_name=\"Nam1\")\n",
    "\n",
    "array = data.values\n",
    "X = array[:,0:data.shape[1]-1]\n",
    "Y = array[:,data.shape[1]-1]\n",
    "Y = Y.astype('int')\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train_1, X_validation_1, Y_train_1, Y_validation_1 = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "model = SVC().fit(X_train_1, Y_train_1)\n",
    "\n",
    "#save model\n",
    "pickle.dump(model, open('nam1.pkl', 'wb'))\n",
    "\n",
    "# used_accuracy_score()\n",
    "import pickle\n",
    "model = pickle.load(open('nam1.pkl', 'rb'))\n",
    "accuracy_score = model.score(X_validation_1, Y_validation_1)\n",
    "print(\"accuracy_score = \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "ulr = \"Data_preprocessing_finish.xlsx\"\n",
    "data = pd.read_excel(ulr, sheet_name=\"Nam2\")\n",
    "\n",
    "array = data.values\n",
    "X = array[:,0:data.shape[1]-1]\n",
    "Y = array[:,data.shape[1]-1]\n",
    "Y = Y.astype('int')\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train_2, X_validation_2, Y_train_2, Y_validation_2 = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "model = SVC().fit(X_train_2, Y_train_2)\n",
    "\n",
    "#save model\n",
    "pickle.dump(model, open('nam2.pkl', 'wb'))\n",
    "\n",
    "# used_accuracy_score()\n",
    "import pickle\n",
    "model = pickle.load(open('nam2.pkl', 'rb'))\n",
    "accuracy_score = model.score(X_validation_2, Y_validation_2)\n",
    "print(\"accuracy_score = \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  1.0\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "ulr = \"Data_preprocessing_finish.xlsx\"\n",
    "data = pd.read_excel(ulr, sheet_name=\"Nam3\")\n",
    "\n",
    "array = data.values\n",
    "X = array[:,0:data.shape[1]-1]\n",
    "Y = array[:,data.shape[1]-1]\n",
    "Y = Y.astype('int')\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train_3, X_validation_3, Y_train_3, Y_validation_3 = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "model = SVC().fit(X_train_3, Y_train_3)\n",
    "\n",
    "#save model\n",
    "pickle.dump(model, open('nam3.pkl', 'wb'))\n",
    "\n",
    "# used_accuracy_score()\n",
    "import pickle\n",
    "model = pickle.load(open('nam3.pkl', 'rb'))\n",
    "accuracy_score = model.score(X_validation_3, Y_validation_3)\n",
    "print(\"accuracy_score = \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "ulr = \"Data_preprocessing_finish.xlsx\"\n",
    "data = pd.read_excel(ulr, sheet_name=\"Nam4\")\n",
    "\n",
    "array = data.values\n",
    "X = array[:,0:data.shape[1]-1]\n",
    "Y = array[:,data.shape[1]-1]\n",
    "Y = Y.astype('int')\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train_4, X_validation_4, Y_train_4, Y_validation_4 = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "model = SVC().fit(X_train_4, Y_train_4)\n",
    "\n",
    "#save model\n",
    "pickle.dump(model, open('nam4.pkl', 'wb'))\n",
    "\n",
    "# used_accuracy_score()\n",
    "import pickle\n",
    "model = pickle.load(open('nam4.pkl', 'rb'))\n",
    "accuracy_score = model.score(X_validation_4, Y_validation_4)\n",
    "print(\"accuracy_score = \", accuracy_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "432b5f7412c9acb8f5a8b2cff6c56a262c8f6f9928f2619ea3392591a4796cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
